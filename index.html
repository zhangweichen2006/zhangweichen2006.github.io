<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Weichen Zhang - ML/DL Researcher</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
        }
        .header {
            text-align: center;
            margin-bottom: 2em;
        }
        .profile-photo {
            width: 200px;
            height: 200px;
            border-radius: 50%;
            margin: 0 auto 1em;
            display: block;
            object-fit: cover;
            border: 3px solid #2c3e50;
        }
        h1 {
            color: #2c3e50;
            margin-bottom: 0.5em;
        }
        .contact-info {
            color: #666;
            margin-bottom: 2em;
        }
        .section {
            margin-bottom: 2em;
        }
        .section-title {
            color: #2c3e50;
            border-bottom: 2px solid #eee;
            padding-bottom: 0.5em;
        }
        .highlights li {
            margin-bottom: 1em;
        }
        .social-links {
            text-align: center;
            margin: 2em 0;
        }
        .social-links a {
            margin: 0 15px;
            color: #2c3e50;
            text-decoration: none;
            font-size: 1.2em;
        }
        .social-links a:hover {
            color: #3498db;
        }
        .social-links i {
            margin-right: 5px;
        }
        .project-card {
            background: #f8f9fa;
            border-radius: 8px;
            padding: 20px;
            margin-bottom: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            transition: transform 0.2s ease-in-out;
        }
        .project-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        .project-title {
            color: #2c3e50;
            margin-bottom: 10px;
            font-size: 1.2em;
            font-weight: bold;
        }
        .project-description {
            margin-bottom: 15px;
            color: #555;
        }
        .publication {
            background: #fff;
            padding: 15px;
            border-left: 4px solid #3498db;
            margin-top: 10px;
            font-size: 0.95em;
            border-radius: 0 4px 4px 0;
        }
        .publication i {
            color: #3498db;
            margin-right: 5px;
        }
        .publication strong {
            color: #2c3e50;
        }
    </style>
</head>
<body>
    <div class="header">
        <img src="assets/profile.png" alt="Weichen Zhang" class="profile-photo">
        <h1>Weichen Zhang</h1>
        <div class="contact-info">
            <p>Ph.D. <i>University of Sydney</i></p>
            <p>Machine Learning and Deep Learning Researcher</p>
        </div>
    </div>

    <div class="section">
        <h2 class="section-title">About Me</h2>
        <p>I am a highly motivated Machine Learning and Deep Learning Researcher and Engineer, currently a Postdoctoral Researcher at the University of Sydney. My core expertise includes enhancing large-scale 3D point cloud analysis, 3D mesh reconstruction, SLAM, and neural network-based segmentation models. Holding a Ph.D. from the University of Sydney with a focus on deep visual transfer learning, I excel in developing and optimizing deep learning algorithms for 2D and 3D visual tasks across both supervised and unsupervised learning paradigms.</p>
    </div>

    <div class="section">
        <h2 class="section-title">Career Highlights</h2>
        <ul class="highlights">
            <li>8+ years of AI and DL/ML research experience in 2D/3D Image/Video/Point Cloud multi-modal multi-domain supervised/unsupervised visual application processing system design.</li>
            <li>3+ years of industry R&D experience at Bodymapp focusing on AWS MLOps pipeline design, 3D reconstruction, neural networks, measurement and recommendation system.</li>
            <li>1 year of technical leading experience at Bodymapp, including method ideation and implementation, arranging meetings, brainstorming, retrospective and managing task priority.</li>
            <li>1 year of tutoring and teaching experience at The University of Sydney, focusing on deep neural networks and transfer learning.</li>
        </ul>
    </div>

    <div class="section">
        <h2 class="section-title">Research Interests</h2>
        <ul>
            <li>2D/3D Visual Applications</li>
            <li>Human Body Reconstruction and Tracking</li>
            <li>Model Generalization</li>
            <li>Deep Visual Transfer Learning</li>
            <li>Multi-sensor and Multi-domain Research</li>
        </ul>
    </div>

    <div class="section">
        <h2 class="section-title">Featured Projects & Publications</h2>

        <div class="project-card">
            <div class="project-title">Precise 3D Mesh Reconstruction (Bodymapp)</div>
            <div class="project-description">Zero-to-One World-Class depth-only (protect privacy) mobile App for accurate scanning, reconstructing, and measuring the human body on various iOS devices (iPhones/iPads).</div>
            <div class="publication">
                <i class="fas fa-patent"></i><strong>[US Patent]</strong> <strong>Zhang, W.,</strong> et al. "Methods for generating a partial three-dimensional representation of a person." (in submission)
            </div>
        </div>

        <div class="project-card">
            <div class="project-title">Cross-domain 3D Object Detection</div>
            <div class="project-description">Pioneering 3D point cloud based Cross-environment Object Detection in Autonomous Driving Scenarios.</div>
            <div class="publication">
                <i class="fas fa-award"></i><strong>[CVPR 21]</strong> <strong>Zhang, W.,</strong> Li, W., & Xu, D. "SRDAN: Scale-aware and range-aware domain adaptation network for cross-dataset 3D object detection."
            </div>
        </div>

        <div class="project-card">
            <div class="project-title">Cross-domain Object Recognition</div>
            <div class="project-description">Collaborative and Adversarial Network for Unsupervised Domain Adaptation with pioneering use of adaptive pseudo labels and adversarial learning (GAN).</div>
            <div class="publication">
                <i class="fas fa-patent"></i><strong>[US Patent 21]</strong> <strong>Zhang, W.,</strong> et al. "Method for training deep neural network and apparatus." U.S. Patent Application No. 17/033,316.
            </div>
            <div class="publication">
                <i class="fas fa-award"></i><strong>[CVPR 18]</strong> <strong>Zhang, W.,</strong> Ouyang, W., Li, W., & Xu, D. "Collaborative and adversarial network for unsupervised domain adaptation."
            </div>
        </div>

        <div class="project-card">
            <div class="project-title">Cross-domain Cross-modality Recognition and Detection</div>
            <div class="project-description">Self-paced Collaborative and Adversarial Network with mutual multi-modal adaptability.</div>
            <div class="publication">
                <i class="fas fa-journal-whills"></i><strong>[T-PAMI 19]</strong> <strong>Zhang, W.,</strong> Xu, D., Ouyang, W., & Li, W. "Self-paced collaborative and adversarial network for unsupervised domain adaptation."
            </div>
        </div>

        <div class="project-card">
            <div class="project-title">Multi-Modality Domain Adaptation</div>
            <div class="project-description">Progressive Modality Cooperation for Multi-Modality Domain Adaptation with missing modality generative model.</div>
            <div class="publication">
                <i class="fas fa-journal-whills"></i><strong>[T-IP 21]</strong> <strong>Zhang, W.,</strong> Xu, D., Ouyang, W. & Zhang, J. "Progressive Modality Cooperation for Multi-Modality Domain Adaptation."
            </div>
        </div>

        <div class="project-card">
            <div class="project-title">Cross-domain Model Compression</div>
            <div class="project-description">Model Compression using Progressive Channel Pruning which is proven effective combining transfer learning.</div>
            <div class="publication">
                <i class="fas fa-journal-whills"></i><strong>[T-CSVT 20]</strong> Guo, J., <strong>Zhang, W.,</strong> Ouyang, W., & Xu, D. "Model Compression using Progressive Channel Pruning."
            </div>
        </div>

        <div class="project-card">
            <div class="project-title">Cross-modality Pose Estimation</div>
            <div class="project-description">3D Hand Pose Estimation with Disentangled Cross-Modal Latent Space and modality generation.</div>
            <div class="publication">
                <i class="fas fa-award"></i><strong>[WACV 20]</strong> Gu, J., Wang, Z., Ouyang, W., <strong>Zhang, W.,</strong> Li, J., & Zhuo, L. "3D Hand Pose Estimation with Disentangled Cross-Modal Latent Space."
            </div>
        </div>
    </div>

    <div class="section">
        <h2 class="section-title">Visitors</h2>
        <div class="visitor-map" style="text-align: center; margin: 20px 0;">
            <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=zhangweichen2006.github.io&cl=ffffff&w=400"></script>
        </div>
    </div>

    <div class="social-links">
        <a href="https://scholar.google.com/citations?user=WaIgpgQAAAAJ&hl=en" target="_blank"><i class="fas fa-graduation-cap"></i>Google Scholar</a>
        <a href="https://github.com/zhangweichen2006" target="_blank"><i class="fab fa-github"></i>GitHub</a>
        <a href="/assets/CV.pdf" target="_blank"><i class="fas fa-file-pdf"></i>Curriculum Vitae</a>
    </div>
</body>
</html>